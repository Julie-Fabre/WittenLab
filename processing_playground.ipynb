{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fda795b",
   "metadata": {},
   "source": [
    "## Processing playground \n",
    "### tracking neurons across days "
   ]
  },
  {
   "cell_type": "code",
   "id": "cae836c0",
   "metadata": {},
   "outputs": [],
   "source": "# Import necessary libraries\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Enable autoreload like in the demo\n%load_ext autoreload\n%autoreload 2\n\n# Import bombcell like in the demo\nimport bombcell as bc\n\nprint(\"Available bombcell functions:\")\nprint([attr for attr in dir(bc) if not attr.startswith('_')])\n\n# UnitMatch imports\nimport UnitMatchPy.bayes_functions as bf\nimport UnitMatchPy.utils as util\nimport UnitMatchPy.overlord as ov\nimport UnitMatchPy.save_utils as su\nimport UnitMatchPy.GUI as gui\nimport UnitMatchPy.assign_unique_id as aid\nimport UnitMatchPy.default_params as default_params"
  },
  {
   "cell_type": "code",
   "id": "326afb5a",
   "metadata": {},
   "outputs": [],
   "source": "## Step 1: Set up file paths\n# KiloSort directories\nKS_dirs = [r'/home/jf5479/cup/Chris/data/cta_backwards/calca_302/2023-04-19/cz_npxl_g0/cz_npxl_g0_imec0/kilosort4',\n           r'/home/jf5479/cup/Chris/data/cta_backwards/calca_302/2023-04-20/cz_npxl_g0/cz_npxl_g0_imec0/kilosort4']\n\n# BombCell output directories - add testing suffix\ncustom_bombcell_paths = [r'/home/jf5479/cup/Chris/data/cta_backwards/calca_302/2023-04-19/cz_npxl_g0/cz_npxl_g0_imec0/bombcell_testing_jf',\n                         r'/home/jf5479/cup/Chris/data/cta_backwards/calca_302/2023-04-20/cz_npxl_g0/cz_npxl_g0_imec0/bombcell_testing_jf']\n\n# Output directory for saving results - add testing suffix\nsave_dir = r'/home/jf5479/cup/Chris/data/cta_backwards/calca_302/unitmatch_output_testing_jf'\nos.makedirs(save_dir, exist_ok=True)\n\nprint(f\"KiloSort directories: {KS_dirs}\")\nprint(f\"BombCell directories: {custom_bombcell_paths}\")\nprint(f\"Output directory: {save_dir}\")"
  },
  {
   "cell_type": "code",
   "id": "34299cec",
   "metadata": {},
   "outputs": [],
   "source": "## Step 2: Run BombCell quality metrics and extract raw waveforms\nprint(\"Starting BombCell processing...\")\n\n# Process each session with BombCell\nbombcell_results = {}\nfor i, session_dir in enumerate(KS_dirs):\n    print(f\"Processing session {i+1}: {session_dir}\")\n    \n    # Find raw data file (.bin) and meta file (.meta) \n    session_path = Path(session_dir).parent\n    raw_files = list(session_path.glob(\"*.ap.bin\"))\n    meta_files = list(session_path.glob(\"*.ap.meta\"))\n    \n    raw_file = str(raw_files[0]) if raw_files else None\n    meta_file = str(meta_files[0]) if meta_files else None\n    \n    print(f\"  Raw file: {raw_file}\")\n    print(f\"  Meta file: {meta_file}\")\n    \n    # Get default BombCell parameters for this session\n    param = bc.default_parameters.get_default_parameters(session_dir, \n                                                        raw_file=raw_file,  # Provide raw file path\n                                                        meta_file=meta_file,  # Provide meta file path\n                                                        kilosort_version=4)  # Adjust based on your KS version\n    \n    # Customize parameters for UnitMatch integration\n    param['extractRaw'] = True  # Ensure raw waveforms are extracted for UnitMatch\n    param['computeDistanceMetrics'] = False  # Disable expensive metrics\n    param['computeDrift'] = False\n    param['saveAsTSV'] = True  # Save results in phy-compatible format\n    \n    # Set BombCell output directory with testing suffix\n    bc_output_dir = Path(session_dir).parent / 'bombcell_testing_jf'\n    \n    try:\n        # Run BombCell - the function should be imported at top level\n        (quality_metrics, param, unit_type, unit_type_string) = bc.run_bombcell(\n            session_dir, bc_output_dir, param\n        )\n        \n        bombcell_results[f'session_{i+1}'] = {\n            'quality_metrics': quality_metrics,\n            'unit_type': unit_type,\n            'unit_type_string': unit_type_string,\n            'param': param,\n            'session_dir': session_dir,\n            'bc_output_dir': str(bc_output_dir)\n        }\n        \n        print(f\"BombCell processing complete for session {i+1}\")\n        print(f\"  - Total units: {len(quality_metrics['phy_clusterID'])}\")\n        print(f\"  - Good units: {sum(np.array(unit_type_string) == 'GOOD')}\")\n        print(f\"  - Results saved to: {bc_output_dir}\")\n        \n    except Exception as e:\n        print(f\"Error processing session {i+1}: {e}\")\n        import traceback\n        traceback.print_exc()\n        continue\n\nprint(\"BombCell processing completed for all sessions.\")"
  },
  {
   "cell_type": "code",
   "id": "4c8dca3f",
   "metadata": {},
   "outputs": [],
   "source": "## Step 3: Prepare data for UnitMatch\nprint(\"Preparing data for UnitMatch...\")\n\n# Get default UnitMatch parameters\nparam = default_params.get_default_param()\n\n# Set up paths for UnitMatch - using the directories defined above\nparam['KS_dirs'] = KS_dirs\n\n# Use BombCell output directories for waveforms and labels\nbc_output_dirs = [bombcell_results[f'session_{i+1}']['bc_output_dir'] for i in range(len(KS_dirs))]\n\n# Get paths from BombCell outputs\nwave_paths, unit_label_paths, channel_pos = util.paths_from_KS(\n    KS_dirs, \n    custom_bombcell_paths=bc_output_dirs\n)\n\n# Get probe geometry\nparam = util.get_probe_geometry(channel_pos[0], param)\n\nprint(f\"Raw waveform paths: {wave_paths}\")\nprint(f\"Unit label paths: {unit_label_paths}\")\nprint(f\"Channel positions loaded: {len(channel_pos)} sessions\")\nprint(\"Data preparation for UnitMatch complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20265e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Run UnitMatch - Data Loading and Parameter Extraction\n",
    "print(\"Starting UnitMatch processing...\")\n",
    "\n",
    "# STEP 0 -- Data preparation\n",
    "print(\"Loading good waveforms...\")\n",
    "waveform, session_id, session_switch, within_session, good_units, param = util.load_good_waveforms(\n",
    "    wave_paths, unit_label_paths, param, good_units_only=True\n",
    ") \n",
    "\n",
    "# You may need to set peak location if it's not automatically detected correctly\n",
    "# param['peak_loc'] = # set as a value if the peak location is NOT ~ half the spike width\n",
    "\n",
    "# Create clus_info containing all unit id/session related info\n",
    "clus_info = {\n",
    "    'good_units': good_units, \n",
    "    'session_switch': session_switch, \n",
    "    'session_id': session_id, \n",
    "    'original_ids': np.concatenate(good_units)\n",
    "}\n",
    "\n",
    "print(f\"Total number of good units: {param['n_units']}\")\n",
    "print(f\"Number of sessions: {len(KS_dirs)}\")\n",
    "\n",
    "# STEP 1 -- Extract parameters from waveforms\n",
    "print(\"Extracting waveform parameters...\")\n",
    "extracted_wave_properties = ov.extract_parameters(waveform, channel_pos, clus_info, param)\n",
    "print(\"Parameter extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: UnitMatch - Metric Calculation and Drift Correction\n",
    "print(\"Calculating similarity metrics and applying drift correction...\")\n",
    "\n",
    "# STEPS 2, 3, 4 -- Extract metric scores with drift correction\n",
    "total_score, candidate_pairs, scores_to_include, predictors = ov.extract_metric_scores(\n",
    "    extracted_wave_properties, session_switch, within_session, param, niter=2\n",
    ")\n",
    "\n",
    "print(f\"Number of candidate pairs: {len(candidate_pairs)}\")\n",
    "print(f\"Scores included: {scores_to_include}\")\n",
    "print(\"Metric calculation and drift correction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: UnitMatch - Naive Bayes Classification\n",
    "print(\"Running Naive Bayes classification...\")\n",
    "\n",
    "# STEP 5 -- Probability analysis\n",
    "# Get prior probability of being a match\n",
    "prior_match = 1 - (param['n_expected_matches'] / param['n_units']**2)\n",
    "priors = np.array((prior_match, 1-prior_match))\n",
    "\n",
    "print(f\"Prior probability of match: {prior_match:.4f}\")\n",
    "\n",
    "# Construct distributions (kernels) for Naive Bayes Classifier\n",
    "labels = candidate_pairs.astype(int)\n",
    "cond = np.unique(labels)\n",
    "score_vector = param['score_vector']\n",
    "parameter_kernels = np.full((len(score_vector), len(scores_to_include), len(cond)), np.nan)\n",
    "\n",
    "parameter_kernels = bf.get_parameter_kernels(scores_to_include, labels, cond, param, add_one=1)\n",
    "\n",
    "# Get probability of each pair being a match\n",
    "probability = bf.apply_naive_bayes(parameter_kernels, priors, predictors, param, cond)\n",
    "\n",
    "# Reshape probability matrix\n",
    "output_prob_matrix = probability[:,1].reshape(param['n_units'], param['n_units'])\n",
    "\n",
    "print(\"Naive Bayes classification complete.\")\n",
    "print(f\"Probability matrix shape: {output_prob_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64df43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Evaluate Results and Apply Threshold\n",
    "print(\"Evaluating UnitMatch results...\")\n",
    "\n",
    "# Evaluate output with different thresholds\n",
    "util.evaluate_output(output_prob_matrix, param, within_session, session_switch, match_threshold=0.75)\n",
    "\n",
    "# Set match threshold (you can experiment with different values)\n",
    "match_threshold = param['match_threshold']  # or set your own value, e.g., 0.75\n",
    "\n",
    "# Apply threshold to create binary match matrix\n",
    "output_threshold = np.zeros_like(output_prob_matrix)\n",
    "output_threshold[output_prob_matrix > match_threshold] = 1\n",
    "\n",
    "# Visualize the thresholded matches\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(output_threshold, cmap='Greys')\n",
    "plt.title(f'Unit Matches (threshold = {match_threshold})')\n",
    "plt.xlabel('Unit Index')\n",
    "plt.ylabel('Unit Index')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Count matches\n",
    "n_matches = np.sum(output_threshold) // 2  # Divide by 2 because matrix is symmetric\n",
    "print(f\"Number of putative matches found: {n_matches}\")\n",
    "print(f\"Match threshold used: {match_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8: Prepare and Launch GUI (Optional)\n",
    "print(\"Preparing data for GUI...\")\n",
    "\n",
    "# Format data for GUI\n",
    "amplitude = extracted_wave_properties['amplitude']\n",
    "spatial_decay = extracted_wave_properties['spatial_decay']\n",
    "avg_centroid = extracted_wave_properties['avg_centroid']\n",
    "avg_waveform = extracted_wave_properties['avg_waveform']\n",
    "avg_waveform_per_tp = extracted_wave_properties['avg_waveform_per_tp']\n",
    "wave_idx = extracted_wave_properties['good_wave_idxs']\n",
    "max_site = extracted_wave_properties['max_site']\n",
    "max_site_mean = extracted_wave_properties['max_site_mean']\n",
    "\n",
    "# Process info for GUI\n",
    "gui.process_info_for_GUI(\n",
    "    output_prob_matrix, match_threshold, scores_to_include, total_score, amplitude, spatial_decay,\n",
    "    avg_centroid, avg_waveform, avg_waveform_per_tp, wave_idx, max_site, max_site_mean, \n",
    "    waveform, within_session, channel_pos, clus_info, param\n",
    ")\n",
    "\n",
    "print(\"GUI data preparation complete.\")\n",
    "print(\"To launch the GUI, run the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc936b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 9: Launch GUI for Manual Curation (Optional)\n",
    "# Uncomment the lines below to run the GUI for manual curation\n",
    "\n",
    "# print(\"Launching UnitMatch GUI...\")\n",
    "# is_match, not_match, matches_GUI = gui.run_GUI()\n",
    "\n",
    "# # If you ran the GUI, curate the matches\n",
    "# matches_curated = util.curate_matches(matches_GUI, is_match, not_match, mode='And')\n",
    "# print(f\"Manual curation complete. Curated matches: {len(matches_curated)}\")\n",
    "\n",
    "print(\"GUI section ready. Uncomment the lines above to run manual curation.\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2b75ed0",
   "metadata": {},
   "outputs": [],
   "source": "## Step 10: Save Results\nprint(\"Saving UnitMatch results...\")\n\n# Get matches from thresholded matrix\nmatches = np.argwhere(output_threshold == 1)\n\n# Assign unique IDs to matched units\nUIDs = aid.assign_unique_id(output_prob_matrix, param, clus_info)\n\n# Create output directory with testing suffix\nunitmatch_output_dir = os.path.join(save_dir, 'unitmatch_results_testing_jf')\nos.makedirs(unitmatch_output_dir, exist_ok=True)\n\n# Save results\n# NOTE: Change 'matches' to 'matches_curated' if you performed manual curation with the GUI\nsu.save_to_output(\n    unitmatch_output_dir, \n    scores_to_include, \n    matches,  # Use matches_curated if you did manual curation\n    output_prob_matrix, \n    avg_centroid, \n    avg_waveform, \n    avg_waveform_per_tp, \n    max_site,\n    total_score, \n    output_threshold, \n    clus_info, \n    param, \n    UIDs=UIDs, \n    matches_curated=None,  # Set to matches_curated if you did manual curation\n    save_match_table=True\n)\n\nprint(f\"Results saved to: {unitmatch_output_dir}\")\nprint(f\"Number of matches saved: {len(matches)}\")\nprint(f\"Unique IDs assigned to {len(UIDs)} units\")\n\n# Print summary\nprint(\"\\n=== PROCESSING SUMMARY ===\")\nprint(f\"BombCell processed {len(KS_dirs)} sessions\")\nprint(f\"UnitMatch analyzed {param['n_units']} good units\")\nprint(f\"Found {n_matches} putative matches\")\nprint(f\"Results saved to: {unitmatch_output_dir}\")\nprint(\"Processing complete!\")"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}